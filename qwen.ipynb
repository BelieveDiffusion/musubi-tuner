{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d61cd191-c05c-4fdf-abf9-d8fc2e899679",
   "metadata": {},
   "source": [
    "# MUSUBI TUNER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57fd336-eac2-4917-ad00-b0ae7ca92467",
   "metadata": {},
   "source": [
    "# Install Musubi Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47275565-07d5-42a2-aee0-1500ef509fcd",
   "metadata": {},
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# root_dir\n",
    "root_dir          = \"/workspace\"\n",
    "drive_dir         = os.path.join(root_dir, \"drive\", \"MyDrive\")\n",
    "repo_dir          = os.path.join(root_dir, \"musubi-tuner\")\n",
    "training_dir      = os.path.join(root_dir, \"fine_tune\")\n",
    "pretrained_model  = os.path.join(root_dir, \"pretrained_model\")\n",
    "vae_dir           = os.path.join(root_dir, \"vae\")\n",
    "lora_dir          = os.path.join(root_dir, \"network_weight\")\n",
    "config_dir        = os.path.join(training_dir, \"config\")\n",
    "output_dir        = os.path.join(training_dir, \"outputs\")\n",
    "tools_dir         = os.path.join(repo_dir, \"tools\")\n",
    "finetune_dir      = os.path.join(repo_dir, \"finetune\")\n",
    "accelerate_config = os.path.join(repo_dir, \"accelerate_config\", \"config.yaml\")\n",
    "\n",
    "repo_url          = \"https://github.com/BelieveDiffusion/musubi-tuner\"\n",
    "branch            = \"dev_20251223\" \n",
    "\n",
    "def clone_repo(url, dir, branch):\n",
    "    if not os.path.exists(dir):\n",
    "       !git clone -b {branch} {url} {dir}\n",
    "\n",
    "def install_dependencies():\n",
    "    !apt update -yqq\n",
    "    !apt install aria2 -yqq\n",
    "    !pip install -e .\n",
    "    !pip install wandb\n",
    "\n",
    "    from accelerate.utils import write_basic_config\n",
    "\n",
    "    if not os.path.exists(accelerate_config):\n",
    "        write_basic_config(save_location=accelerate_config)\n",
    "\n",
    "def prepare_environment():\n",
    "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "def main():\n",
    "    os.chdir(root_dir)\n",
    "    clone_repo(repo_url, repo_dir, branch)\n",
    "    os.chdir(repo_dir)\n",
    "    for dir in [training_dir, config_dir, pretrained_model, vae_dir, output_dir]:\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "    install_dependencies()\n",
    "    prepare_environment()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29066e0b-e268-4b58-9ea4-3893bbe516fe",
   "metadata": {},
   "source": [
    "# Download Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1c8656-4323-4813-a785-6cee93bac903",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import subprocess\n",
    "from urllib.parse import urlparse, unquote\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(root_dir)\n",
    "\n",
    "HUGGINGFACE_TOKEN = \"\"\n",
    "MODEL_URL    = \"https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_bf16.safetensors\"\n",
    "#MODEL_URL    = \"https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_edit_2509_bf16.safetensors\"\n",
    "VAE_URL      = \"https://huggingface.co/Qwen/Qwen-Image/resolve/main/vae/diffusion_pytorch_model.safetensors\"\n",
    "TE_URL     = \"https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/blob/main/split_files/text_encoders/qwen_2.5_vl_7b.safetensors\"\n",
    "\n",
    "def get_supported_extensions():\n",
    "    return tuple([\".ckpt\", \".safetensors\", \".pt\", \".pth\"])\n",
    "\n",
    "def get_filename(url, bearer_token, quiet=True):\n",
    "    headers = {\"Authorization\": f\"Bearer {bearer_token}\"}\n",
    "    response = requests.get(url, headers=headers, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    if 'content-disposition' in response.headers:\n",
    "        content_disposition = response.headers['content-disposition']\n",
    "        filename = re.findall('filename=\"?([^\"]+)\"?', content_disposition)[0]\n",
    "    else:\n",
    "        url_path = urlparse(url).path\n",
    "        filename = unquote(os.path.basename(url_path))\n",
    "\n",
    "    return filename\n",
    "\n",
    "def parse_args(config):\n",
    "    args = []\n",
    "\n",
    "    for k, v in config.items():\n",
    "        if k.startswith(\"_\"):\n",
    "            args.append(f\"{v}\")\n",
    "        elif isinstance(v, str) and v is not None:\n",
    "            args.append(f'--{k}={v}')\n",
    "        elif isinstance(v, bool) and v:\n",
    "            args.append(f\"--{k}\")\n",
    "        elif isinstance(v, float) and not isinstance(v, bool):\n",
    "            args.append(f\"--{k}={v}\")\n",
    "        elif isinstance(v, int) and not isinstance(v, bool):\n",
    "            args.append(f\"--{k}={v}\")\n",
    "\n",
    "    return args\n",
    "\n",
    "def aria2_download(dir, filename, url, token):\n",
    "    user_header = f\"Authorization: Bearer {token}\"\n",
    "\n",
    "    aria2_config = {\n",
    "        \"console-log-level\"         : \"error\",\n",
    "        \"summary-interval\"          : 10,\n",
    "        \"header\"                    : user_header if \"huggingface.co\" in url else None,\n",
    "        \"continue\"                  : True,\n",
    "        \"max-connection-per-server\" : 16,\n",
    "        \"min-split-size\"            : \"1M\",\n",
    "        \"split\"                     : 16,\n",
    "        \"dir\"                       : dir,\n",
    "        \"out\"                       : filename,\n",
    "        \"_url\"                      : url,\n",
    "    }\n",
    "    aria2_args = parse_args(aria2_config)\n",
    "    subprocess.run([\"aria2c\", *aria2_args])\n",
    "\n",
    "def download(url, dst, token):\n",
    "\n",
    "    if url.startswith(\"/workspace\"):\n",
    "        return url\n",
    "\n",
    "    filename = get_filename(url, token, quiet=False)\n",
    "    filepath = os.path.join(dst, filename)\n",
    "\n",
    "    if \"huggingface.co\" in url:\n",
    "        if \"/blob/\" in url:\n",
    "            url = url.replace(\"/blob/\", \"/resolve/\")\n",
    "                \n",
    "        aria2_download(dst, filename, url, token)\n",
    "    else:\n",
    "        aria2_download(dst, filename, url, token)\n",
    "\n",
    "    return filepath\n",
    "\n",
    "def main():\n",
    "    global model_path, vae_path, te_path\n",
    "\n",
    "    model_path = vae_path = te_path = None\n",
    "\n",
    "    download_targets = {\n",
    "        \"model\" : (MODEL_URL, pretrained_model),\n",
    "        \"vae\"   : (VAE_URL, vae_dir),\n",
    "        \"te\"  : (TE_URL, pretrained_model),\n",
    "    }\n",
    "    selected_files = {}\n",
    "\n",
    "    for target, (url, dst) in download_targets.items():\n",
    "        if url:\n",
    "            downloader = download(url, dst, HUGGINGFACE_TOKEN)\n",
    "            selected_files[target] = downloader\n",
    "\n",
    "            if target == \"model\":\n",
    "                model_path = selected_files[\"model\"] if not downloader else downloader\n",
    "            elif target == \"vae\":\n",
    "                vae_path = selected_files[\"vae\"] if not downloader else downloader\n",
    "            elif target == \"te\":\n",
    "                te_path = selected_files[\"te\"] if not downloader else downloader\n",
    "\n",
    "    for category, path in {\n",
    "        \"model\": model_path,\n",
    "        \"vae\": vae_path,\n",
    "        \"te\": vae_path,\n",
    "    }.items():\n",
    "        if path is not None and os.path.exists(path):\n",
    "            print(f\"Selected {category}: {path}\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525cdc14-d546-4cf4-a854-0877b65bb75f",
   "metadata": {},
   "source": [
    "# Directory Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63254a56-77e9-45d5-ac58-745a70c2459e",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "train_data_dir = \"/workspace/fine_tune/train_data\"\n",
    "\n",
    "os.makedirs(train_data_dir, exist_ok=True)\n",
    "print(f\"Your train data directory : {train_data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5062b8e7-a53c-4072-983e-45d41d8cf771",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeba204-3abe-4e5e-af6f-3cac048e2407",
   "metadata": {},
   "source": [
    "## Unzip Dataset\n",
    "If your dataset is in a `zip` file and has been uploaded to a location, use this section to extract it. The dataset will be downloaded and automatically extracted to `train_data_dir` if `unzip_to` is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "240535e0-b9c0-4e17-b278-c8df0dc56ca5",
   "metadata": {},
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "zipfile_url  = \"\"\n",
    "unzip_to     = \"\"\n",
    "\n",
    "if unzip_to:\n",
    "    os.makedirs(unzip_to, exist_ok=True)\n",
    "else:\n",
    "    unzip_to = train_data_dir\n",
    "\n",
    "def extract_dataset(zip_file, output_path):\n",
    "    with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(output_path)\n",
    "        \n",
    "def remove_files(train_dir, files_to_move):\n",
    "    for filename in os.listdir(train_dir):\n",
    "        file_path = os.path.join(train_dir, filename)\n",
    "        if filename in files_to_move:\n",
    "            if not os.path.exists(file_path):\n",
    "                shutil.move(file_path, training_dir)\n",
    "            else:\n",
    "                if os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "                else:\n",
    "                    os.remove(file_path)\n",
    "\n",
    "zip_file = download(zipfile_url, root_dir, HUGGINGFACE_TOKEN)\n",
    "extract_dataset(zip_file, unzip_to)\n",
    "os.remove(zip_file)\n",
    "\n",
    "files_to_move = (\n",
    "    \"meta_cap.json\",\n",
    "    \"meta_cap_dd.json\",\n",
    "    \"meta_lat.json\",\n",
    "    \"meta_clean.json\",\n",
    "    \"__MACOSX\",\n",
    ")\n",
    "\n",
    "remove_files(train_data_dir, files_to_move)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e29913-5b62-455b-bd53-d293ee7c9840",
   "metadata": {},
   "source": [
    "# Bucketing and Latents Caching and Training\n",
    "This code will create buckets based on the `bucket_resolution` provided for multi-aspect ratio training, and then convert all images within the `train_data_dir` to latents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e521a3f-7b1b-4214-8806-2df6a12f98a5",
   "metadata": {},
   "source": [
    "accelerate_conf = {\n",
    "    \"mixed_precision\": \"bf16\",\n",
    "    \"num_cpu_threads_per_process\": 1,\n",
    "    \"num_processes\": 8,\n",
    "    \"num_machines\": 1,\n",
    "    \"multi_gpu\": True,\n",
    "    \"gpu_ids\": \"0,1,2,3,4,5,6,7\"\n",
    "}\n",
    "\n",
    "train_conf = {\n",
    "    \"dit\": \"/workspace/pretrained_model/qwen_image_bf16.safetensors\",\n",
    "    \"vae\": \"/workspace/vae/diffusion_pytorch_model.safetensors\",\n",
    "    \"text_encoder\": \"/workspace/pretrained_model/qwen_2.5_vl_7b.safetensors\",\n",
    "    \"dataset_config\": \"/workspace/musubi-tuner/dataset_1024_bs2.toml\",\n",
    "    \"sdpa\": True,\n",
    "    \"mixed_precision\": \"bf16\",\n",
    "    \"timestep_sampling\": \"shift\",\n",
    "    \"weighting_scheme\": None,\n",
    "    \"discrete_flow_shift\": 2.2,\n",
    "    \"optimizer_type\": \"adamw8bit\",\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"max_data_loader_n_workers\": 2,\n",
    "    \"persistent_data_loader_workers\": True,\n",
    "    \"network_module\": \"networks.lora_qwen_image\",\n",
    "    \"network_dim\": 128,\n",
    "    \"network_alpha\": 128,\n",
    "    \"max_train_epochs\": 16,\n",
    "    \"save_every_n_epochs\": 1,\n",
    "    \"seed\": 42,\n",
    "    \"output_name\": \"Beauty_09_FB\",\n",
    "    \"output_dir\": \"/workspace/fine_tune/outputs\",\n",
    "    \"log_with\": \"wandb\",\n",
    "    \"log_tracker_name\": \"Beauty_09_FB\",\n",
    "    \"lr_scheduler\": \"constant\",\n",
    "    \"max_grad_norm\": 0.0,\n",
    "    \"wandb_api_key\": \"\",\n",
    "    \"sample_every_n_steps\": 25,\n",
    "    \"sample_at_first\": True,\n",
    "    \"sample_prompts\": \"/workspace/musubi-tuner/prompts.txt\",\n",
    "}\n",
    "\n",
    "def generate_args(config):\n",
    "    args = \"\"\n",
    "    for k, v in config.items():\n",
    "        if k.startswith(\"_\"):\n",
    "            args += f'\"{v}\" '\n",
    "        elif isinstance(v, str):\n",
    "            args += f'--{k}=\"{v}\" '\n",
    "        elif isinstance(v, bool) and v:\n",
    "            args += f\"--{k} \"\n",
    "        elif isinstance(v, float) and not isinstance(v, bool):\n",
    "            args += f\"--{k}={v} \"\n",
    "        elif isinstance(v, int) and not isinstance(v, bool):\n",
    "            args += f\"--{k}={v} \"\n",
    "    return args.strip()\n",
    "\n",
    "accelerate_args = generate_args(accelerate_conf)\n",
    "train_args = generate_args(train_conf)\n",
    "\n",
    "final_args = f\"accelerate launch {accelerate_args} qwen_image_train_network.py {train_args}\"\n",
    "\n",
    "os.chdir(repo_dir)\n",
    "!{final_args}\n",
    "\n",
    "# Cache latents\n",
    "#!python \"src/musubi_tuner/qwen_image_cache_latents.py\" --dataset_config \"/workspace/musubi-tuner/dataset_1024_bs2.toml\" --vae \"/workspace/vae/diffusion_pytorch_model.safetensors\" --skip_existing\n",
    "\n",
    "# Cache text encodings\n",
    "#!python \"src/musubi_tuner/qwen_image_cache_text_encoder_outputs.py\" --dataset_config \"/workspace/musubi-tuner/dataset_1024_bs2.toml\" --text_encoder \"/workspace/pretrained_model/qwen_2.5_vl_7b.safetensors\" --skip_existing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
